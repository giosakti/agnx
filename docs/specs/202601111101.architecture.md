# Agnx Architecture

This document describes Agnx's internal architecture, including the runtime, services, gateway, and provider systems.

## Overview (At a Glance)

- **Durable, portable agents**: agent definitions are transparent YAML files + Markdown for unstructured content (see [Agnx Agent Format](./202601111200.agnx-agent-format.md)).
- **Stateless by default**: the runtime can crash/restart without hidden server-side state.
- **File-based state by default**: sessions, memory, and artifacts are persisted as files; external backends are optional.
- **Standards-first**: Agent Protocol API + MCP tools + A2A Agent Card for discovery.

## Design Principle: Stateless Like nginx

Agnx follows the nginx model:
- **Agent definitions are files** (or pushed via Admin API and persisted as files)
- **Stateless by default** — crash and restart, no hidden runtime state
- **File-based state by default** — session, memory, and artifacts are durable, portable files; external backends are optional

## Core Concepts

### Agent

An agent is defined by a transparent YAML file with unstructured content (e.g. prompts, instructions) stored as Markdown files. See [Agnx Agent Format](./202601111200.agnx-agent-format.md) for the full specification.

### Task

A task is a goal given to an agent (Agent Protocol concept):

```json
{
  "task_id": "task_xyz789",
  "input": "Summarize the latest news about AI agents",
  "agent_id": "agent_abc123",
  "status": "running",
  "steps": [...]
}
```

### Step

A step is one unit of work within a task:

```json
{
  "step_id": "step_001",
  "task_id": "task_xyz789",
  "input": "Search for AI agent news",
  "output": "Found 5 relevant articles...",
  "status": "completed"
}
```

### Memory

Memory persists across conversations:

```yaml
memory:
  # Short-term: recent conversation context
  short_term:
    backend: buffer
    max_tokens: 4000

  # Long-term: facts, preferences, learned information
  long_term:
    backend: filesystem     # Default, file-based state (portable)
    path: ./.agnx/memory/  # Markdown/JSON files (portable)
    # backend: mem0         # External backend (optional)
    # backend: postgres     # External backend (optional)
```

## High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                           Agnx                                 │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    Agent Registry                       │    │
│  │  In-memory map of loaded agents (from files or API)     │    │
│  │  - Lazy loading with LRU cache for scale                │    │
│  │  - Supports thousands of agents per instance            │    │
│  └─────────────────────────────────────────────────────────┘    │
│         │                │                      │               │
│         ▼                ▼                      ▼               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐  │
│  │   HTTP API  │  │  Admin API  │  │         CLI             │  │
│  │  (Agent     │  │  (Deploy/   │  │  (agnx serve/chat/run) │  │
│  │  Protocol)  │  │   Manage)   │  │                         │  │
│  └──────┬──────┘  └──────┬──────┘  └────────────┬────────────┘  │
│         │                │                      │               │
│         └────────────────┼──────────────────────┘               │
│                          │                                      │
│                          ▼                                      │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                       Runner                            │    │
│  │  - Manages event loop                                   │    │
│  │  - Processes events from execution logic                │    │
│  │  - Commits state via Services                           │    │
│  │  - Streams responses to clients                         │    │
│  └─────────────────────────────────────────────────────────┘    │
│         │                │                      │               │
│         ▼                ▼                      ▼               │
│  ┌───────────┐    ┌───────────┐         ┌───────────┐           │
│  │    LLM    │    │   Tools   │         │ Services  │           │
│  │ Interface │    │   (MCP)   │         │ (Session, │           │
│  │           │    │           │         │  Memory,  │           │
│  │           │    │           │         │  Artifact)│           │
│  └───────────┘    └───────────┘         └───────────┘           │
│         │                │                      │               │
│         ▼                ▼                      ▼               │
│  ┌───────────┐    ┌───────────┐         ┌───────────┐           │
│  │ OpenRouter│    │MCP Server │         │ Filesystem│           │
│  │ OpenAI    │    │(external) │         │ (default) │           │
│  │ Anthropic │    │           │         │ External  │           │
│  │ Ollama    │    │           │         │ (opt.)    │           │
│  └───────────┘    └───────────┘         └───────────┘           │
└─────────────────────────────────────────────────────────────────┘
```

## Runtime Architecture (Event Loop Pattern)

Agnx uses a **simple event loop pattern** for execution.

### Core Agent Loop

```
User Message → LLM Call → Tool Calls? → Execute Tools → Feed Results → Repeat
                              │                              │
                              └── No tools ──────────────────┘
                                     │
                                     ▼
                              Return Response
```

This is intentionally minimal. No max step limits, no complex orchestration knobs. Complexity is added only when real use cases demand it.

However, Agnx is **safe by default**: the Runner enforces execution budgets (e.g. max wall time, token budget, tool-call budget) and supports cancellation to prevent runaway loops.

### Full Runtime Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                        Agnx Runtime                            │
│                                                                 │
│  User Input ───────► Runner ─────────────────► Services         │
│       │              (Event Processor)         (pluggable)      │
│       │                   │                        │            │
│       │              Event Loop              ┌─────┴─────┐      │
│       │              (Ask/Yield)             │           │      │
│       │                   │            SessionService    │      │
│       │                   ▼            MemoryService     │      │
│       │            Execution Logic     ArtifactService   │      │
│       │            (Agent, LLM,              │           │      │
│       │             Tools, Callbacks)        ▼           │      │
│       │                   │              Storage         │      │
│       ◄───────────────────┘              (Filesystem,    │      │
│      Stream<Event>                        External)      │      │
└─────────────────────────────────────────────────────────────────┘
```

### Key Components

| Component | Description |
|-----------|-------------|
| **Runner** | Orchestrator that manages event loop, receives queries, processes events |
| **Event Loop** | Ask/Yield pattern between Runner and Execution Logic |
| **Execution Logic** | Agents, LLM calls, tools, callbacks |
| **Services** | Pluggable backends for session, memory, artifacts |
| **Events** | Messages carrying content + details (separated for LLM vs UI) |

### Event Loop Flow

1. Runner receives user query, updates session history
2. Runner asks Execution Logic (agent) to process
3. Agent yields events (partial responses, tool calls, state changes)
4. Runner processes each event (commits state, streams to client)
5. Runner signals agent to resume
6. Repeat until agent yields final event

### Tool Result Structure

```rust
pub struct ToolResult {
    pub content: String,           // For LLM consumption
    pub details: serde_json::Value, // For UI/client rendering
    pub error: Option<String>,
}
```

**Benefits:**
- Streaming LLM responses with partial events
- State changes guaranteed committed before execution resumes
- Tool execution with proper side-effect handling
- Graceful cancellation support
- Clear separation of LLM content vs UI metadata

## Services Layer

Services handle all stateful operations. Built-in state is file-based (filesystem); external backends are optional:

```yaml
# agnx.yaml
services:
  session:
    backend: filesystem       # default (file-based)
    path: ./.agnx/sessions/  # JSON files (relative, portable)
    # backend: postgres       # external (optional)
    # backend: redis          # external (optional)

  memory:
    backend: filesystem       # default (file-based)
    path: ./.agnx/memory/    # Markdown/JSON files (relative, portable)
    # backend: mem0           # external (optional)
    # backend: postgres       # external (optional)

  artifacts:
    backend: filesystem       # default (file-based)
    path: ./.agnx/artifacts/ # (relative, portable)
    # backend: s3             # external (optional)
    # backend: gcs            # external (optional)
```

| Service | Purpose | Default Backend |
|---------|---------|-----------------|
| **SessionService** | Conversation threads, message history | Filesystem |
| **MemoryService** | Long-term knowledge, facts, entities | Filesystem |
| **ArtifactService** | Files, generated outputs | Filesystem |

## Agent Loading Modes

```yaml
# agnx.yaml
agents:
  # Mode 1: File-based (GitOps-friendly)
  static:
    path: ./.agnx/agents
    watch: true  # Auto-reload on file changes

  # Mode 2: API-deployed / dynamically managed (persisted for restart recovery)
  dynamic:
    path: ./.agnx/sys/dyn_agents

  # Lazy loading for scale (thousands of agents)
  lazy_load: true
  cache_size: 1000  # LRU cache
```

## Gateway Component

The Gateway handles external messaging providers and routes to agents.

For the MVP, the gateway is deliberately **in-tree and simple**: providers ship with Agnx, and the `Provider` interface is the stable seam. This keeps the core stable and avoids a premature plugin ecosystem.

### Provider Interface

All providers implement a common trait:

```rust
// src/gateway/provider.rs
#[async_trait]
pub trait Provider: Send + Sync {
    // Identity
    fn name(&self) -> &str;
    fn provider_type(&self) -> ProviderType; // Telegram, WhatsApp, Discord, Web, Cli

    // Lifecycle
    async fn start(&self) -> Result<()>;
    async fn stop(&self) -> Result<()>;
    fn health(&self) -> HealthStatus;

    // Messaging
    async fn send(&self, msg: OutgoingMessage) -> Result<()>;
    fn on_message(&self, handler: Box<dyn MessageHandler>);

    // Optional capabilities
    fn supports_media(&self) -> bool;
    fn supports_streaming(&self) -> bool;
    fn max_message_length(&self) -> usize;
}

pub type MessageHandler = dyn Fn(IncomingMessage) -> Pin<Box<dyn Future<Output = Result<()>> + Send>> + Send + Sync;

pub struct IncomingMessage {
    pub provider_type: ProviderType,
    pub provider_msg_id: String,
    pub chat_id: String,
    pub user_id: String,
    pub text: String,
    pub media: Vec<Media>,
    pub metadata: HashMap<String, serde_json::Value>,
    pub timestamp: DateTime<Utc>,
}

pub struct OutgoingMessage {
    pub chat_id: String,
    pub text: String,
    pub media: Vec<Media>,
    pub metadata: HashMap<String, serde_json::Value>,
}
```

### Built-in Providers

| Provider | Status | Library | Notes |
|----------|--------|---------|-------|
| **Telegram** | v0.1 | [teloxide](https://github.com/teloxide/teloxide) | Bot API, full-featured |
| **Web** | v0.1 | Built-in HTTP/WebSocket | Optional web transport (no bundled UI) |
| **CLI** | v0.1 | Built-in | Interactive terminal |
| **WhatsApp** | Future | TBD | Web protocol |
| **Discord** | Future | [serenity](https://github.com/serenity-rs/serenity) | Bot API |
| **Slack** | Future | [slack-morphism](https://github.com/abdolence/slack-morphism-rust) | Bot API |

### Adding New Providers

For v1.0, adding a new provider requires modifying Agnx core:

1. Implement the `Provider` trait in `src/gateway/providers/<name>.rs`
2. Register the provider in `src/gateway/registry.rs`
3. Add configuration parsing in `src/config.rs`
4. Update documentation

**Future consideration (plugin path, not MVP):** If the requirement is there, add an **out-of-process Provider protocol** (HTTP/gRPC) and ship an `ExternalProvider` adapter that implements `Provider` by talking to that process. This enables third-party "provider plugins" with independent release cycles.

Milestone-level sketch:
- Define a versioned `Provider` RPC contract (send, health, capabilities)
- Define an inbound message stream/callback channel (provider → gateway)
- Load external providers via config (command/path/URL) and treat them like built-ins

We won’t build this until there’s clear need; MCP/CLI tools are the preferred extensibility path for most integrations.

## Tools

### Skills vs MCP: When to Use Each

**Skills (Markdown-based):**
- Agent reads README on-demand, calls via bash
- More token-efficient (no upfront schema dump)
- Simpler to create (just a script + README)
- Visible and debuggable
- Best for: Simple integrations, personal tools, quick extensions

**MCP (Protocol-based):**
- Type-safe tool definitions
- Streaming support
- Ecosystem of pre-built servers
- Better for: Complex integrations, third-party tools, production use

**Agnx approach:** Support both. Let users choose the right tool for their needs.

## Standards Alignment

| Standard | How Agnx Aligns |
|----------|------------------|
| **[Agent Protocol](https://agentprotocol.ai/)** | Implements task/step management endpoints (canonical prefix: `/api/v1/`) |
| **[A2A Protocol](https://a2a-protocol.org/)** | Agent Card for discovery, future inter-agent communication |
| **[Open Agent Spec](https://arxiv.org/abs/2510.04173v3)** | Agent definition format inspired by OAS |
| **[MCP](https://modelcontextprotocol.io/)** | Tools integrate via MCP protocol |
| **[AGENTS.md](https://openai.com/index/agentic-ai-foundation/)** | Supports AGENTS.md for repository context |
| **OpenAPI** | API documented with OpenAPI spec |

### A2A Agent Card Support

Agnx agents can expose an [A2A Agent Card](https://a2a-protocol.org/latest/specification/) for discovery by other agents or orchestrators:

```
GET /agents/{name}/.well-known/agent.json
```

The Agent Card is auto-generated from the agent's PAF definition, providing:
- Agent identity and description
- Supported capabilities (streaming, tools, memory)
- Skills as A2A "skills" with input/output modes
- Security requirements

This enables future multi-agent scenarios where agents can discover and communicate with each other using the A2A protocol.

## Tech Stack

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Language** | Rust | Fast, small binaries (<5MB), no runtime, excellent ARM support, memory-safe |
| **HTTP** | `axum` | Async, performant, production-ready |
| **CLI** | `clap` | Standard Rust CLI library |
| **Config** | YAML (structured) + Markdown (unstructured) | YAML for structured config; Markdown for prompts/instructions |
| **Serialization** | `serde` | De facto Rust standard |
| **Default state store** | File-based (filesystem) | File-first, portable, zero dependencies |
| **LLM Client** | Custom (`reqwest`) | No heavy SDK dependencies |
| **MCP Client** | Custom | Implement MCP protocol |

## Directory Structure

```
agnx/
├── src/
│   ├── main.rs                  # CLI entrypoint
│   ├── config.rs                # Load agnx.yaml, apply defaults
│   ├── build_info.rs            # Build metadata
│   ├── response.rs              # Response types
│   ├── handlers/                # HTTP handlers
│   │   ├── mod.rs
│   │   ├── health.rs            # Health check endpoints
│   │   ├── version.rs           # Version endpoint
│   │   └── agents.rs            # Agent endpoints
│   ├── gateway/                 # Gateway module (future)
│   │   ├── mod.rs
│   │   ├── provider.rs          # Provider trait
│   │   ├── registry.rs          # Provider registry
│   │   └── providers/
│   │       ├── telegram.rs      # Telegram provider
│   │       ├── web.rs           # Web chat provider
│   │       └── cli.rs           # CLI provider
│   ├── runtime/                 # Runtime module (future)
│   │   ├── mod.rs
│   │   ├── runner.rs            # Event loop orchestrator
│   │   └── event.rs             # Event types
│   ├── agent/                   # Agent module (future)
│   │   ├── mod.rs
│   │   ├── loader.rs            # Load agent.yaml
│   │   ├── executor.rs          # Execution logic
│   │   └── spec.rs              # Agent spec types
│   ├── storage/                 # Storage module (future)
│   │   ├── mod.rs
│   │   ├── file.rs              # File-based storage
│   │   └── external/
│   │       ├── postgres.rs
│   │       ├── redis.rs
│   │       └── s3.rs
│   ├── llm/                     # LLM module (future)
│   │   ├── mod.rs
│   │   ├── openrouter.rs
│   │   ├── openai.rs
│   │   ├── anthropic.rs
│   │   └── ollama.rs
│   └── tools/                   # Tools module (future)
│       ├── mod.rs
│       ├── mcp.rs
│       └── builtin/
├── examples/
│   ├── agents/                  # Example agents
│   └── docker-compose.yml       # Example deployment
├── docs/
│   ├── specs/                   # Design documents
│   └── examples/                # Example skills
├── Dockerfile
├── Cargo.toml
├── Cargo.lock
├── LICENSE                      # MIT
└── README.md
```
